{"componentChunkName":"component---src-pages-use-cases-gitops-index-mdx","path":"/use-cases/gitops/","result":{"pageContext":{"frontmatter":{"title":"Event-driven solution GitOps approach","description":"Event-driven solution GitOps approach"},"relativePagePath":"/use-cases/gitops/index.mdx","titleType":"append","MdxNode":{"id":"7892f491-a414-5a7a-8211-91034177cc17","children":[],"parent":"9ae7fdd9-5261-59d4-acfc-03b3f63ff905","internal":{"content":"---\ntitle: Event-driven solution GitOps approach\ndescription: Event-driven solution GitOps approach\n---\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 2/15/2022</strong>\n</InlineNotification>\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Components for GitOps</AnchorLink>\n  <AnchorLink>High-level architecture view</AnchorLink>\n  <AnchorLink>Examples of solution GitOps</AnchorLink>\n</AnchorLinks>\n\n**Audience**: Architects, Application developers, Site reliability engineers, Administrators\n\n## Overview\n\nThe purpose of the tutorial is to teach architects, developers and operations staff how to deploy a production-ready \nevent-driven solution  [OpenShift Container Platform](http://openshift.com). It makes\nextensive use of the [IBM Cloud Pak for Integration\n(CP4I)](https://cloud.ibm.com/docs/cloud-pak-integration) and other [cloud\nnative technologies]((https://landscape.cncf.io/)) such as Tekton, Kustomize,\nArgoCD, Prometheus, Grafana and Kibana.\n\nGitOps is a declarative way to implement continuous deployment for cloud-native applications. The Red Hat® OpenShift® Container \nPlatform offers the [OpenShift GitOps operator](https://docs.openshift.com/container-platform/4.7/cicd/gitops/understanding-openshift-gitops.html), \nwhich manages the entire lifecycle for [Argo CD](https://argoproj.github.io/argo-cd/) and its components.\n\n\nArgo applications are added to the Argo CD server. An application defines the source of the Kubernetes resources and the target cluster where \nthose resources should be deployed. The Argo CD server \"installs\" a Cloud Pak by synchronizing the applications representing the Cloud Pak into \nthe target cluster.\n\n### System context\n\nA [system context](https://en.wikipedia.org/wiki/System_context_diagram) diagram\nhelps us understand how our system interacts with its different users and\nother systems. For a generic event-driven solution the diagram looks like\n\n![system-context](./images/eda-gitops.png)\n\nWe can see the different entities that interact with a typical event-driven solution deployment.\nThese include users as well as applications and messaging as a service infrastructure which includes\nevent backbone, queueing systems, schema registry, API management, governance platform and monitoring components.\n\nWe'll be developing the Event-driven solution deployment at the centre of the diagram. We can see\nthat it connects applications to systems and infrastructure. Its users are at least\ndevelopers, SREs, Kubernetes administrators, architects...\n\n## Components for GitOps\n\nThe following diagram shows the technical components used in a typical event-driven solution production\ndeployment.\n\n![components](./images/components.png)\n(*the source code of this diagram is a ``.drawio` format and is in the [diagrams folder](https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/src/pages/use-cases/gitops/diagrams).*)\n\nThe diagram organizes the components according to when they are introduced in system development (earlier or later) \nand whether they are a relatively high level application-oriented component, or a relatively low level system- oriented component.\nFor example, GitHub is a system component that is fundamental to how we structure the event-driven solution deployment. \nIn contrast, streaming or event-driven applications are higher level components, and requires other components to be deployed prior to them.\n\nThe color coding illustrates that blue components are part of the solution, red are part of the GitOps on OpenShift and green components\nare externals to OpenShit cluster, most likely event if they could be.\nKustomize represents way to define deployment, and Sealed secret is a service to manage secrets.\n\nAs part of the later components to deploy, we have addressed everything to monitor the solution and the infrastructure. \n\nHere is a brief introduction of those components:\n\n### Event-driven applications\n\nThose applications are supporting business logic, microservice based, and using Reactive messaging, MQ or Kafka APIs. Those applications \nprovide OpenAPIs to the mobile or web applications but also AsyncAPI when they produce events to Kafka or messages to MQ. OpenAPI and AsyncAPI\ndefinitions are managed by API manager and event end-point manager. \n\nSchema definitions are managed by a **Schema Registry**.\n\n--- \n\n### Event-streaming applications\n\nThose applications are also supporting business logic, but more with stateful processing using [Kafka Stream](/technology/kafka-streams/) APIs or \ndifferent product such as [Apache Flink](/technology/flink/).\n\n---\n\n### Queue manager\n\nA queue manager provides queueing services via one of the many MQ APIs. A queue\nmanager hosts the queues that store the messages produced and consumed by\nconnected applications and systems. Queue managers can be connected together via\nnetwork channels to allow messages to flow between disparate systems and\napplications on different platforms including on-premise and cloud systems.\n\n---\n\n## OpenShift GitOps or ArgoCD\n\nOpenShift GitOps (ArgoCD) is used for the continuous deployment of software components to the\nKubernetes cluster. OpenShift GitOps watches a Git repository for new or changed\nKubernetes resource definitions, and applies them to a cluster. In this\nway, OpenShift GitOps ensures that the component configuration stored in GitHub always\nreflects the state of the cluster.\n\nOpenShift GitOps also has the added benefit of being able to monitor resources that it has\ndeployed to ensure that if they drift from their desired values, they will be\nautomatically restored to those values by OpenShift GitOps.\n\n---\n\n### OpenShift Pipelines or Tekton\n\nOpenShift Pipelines (Tekton) is used to automate manual tasks using the concept of a pipeline. A\npipeline comprises a set of tasks that are executed in a specified order in\norder to accomplish a specific objective.\n\nWe use pipelines as part of the continuous integration process to build, test\nand deliver event-driven applications ready for deployment by OpenShift GitOps.\n\n\n### Queue manager\n\nA queue manager provides queueing services via one of the many MQ APIs. A queue\nmanager hosts the queues that store the messages produced and consumed by\nconnected applications and systems. Queue managers can be connected together via\nnetwork channels to allow messages to flow between disparate systems and\napplications on different platforms including on-premise and cloud systems.\n\n---\n\n### Sealed secrets\n\nVery often a component has a Kubernetes secret associated with it. Inside the\nsecret might be a private key to access the IBM entitled container registry, for\nexample.  For obvious reasons, we don't want to store the secrets in GitHub with\nthe rest of the configuration.\n\nA [sealed secret](https://github.com/bitnami-labs/sealed-secrets) solves this problem by introducing a new kind of Kubernetes\nresource. A sealed secret is created from a regular secret, and can be safely\nstored in a Git repository. A deployment time, the sealed secret controller will\nrecreate the secret in its original form so that it can be access by components\nwith the appropriate RBAC authority.\n\n---\n\n### Image Registry\n\nOpenShift contains a registry for storing container images. Images are built and stored by OpenShift Pipelines\n as part of the CICD process. Tekton pipelines and ArgoCD also retrieve\nthe latest best images from the image registry to ensure that what's being\ntested or deployed in higher environments is the same as what's tested in\ndevelopment environments.\n\nWe often refer to uploading images as *pushing* and downloading images as\n*pulling*.\n\n---\n\n### Cert manager\n\nManaging certificates is a difficult process; certificate creation requires a\nCertificate Authority (CA), certificates expire after a period of time, and\nprivate keys can sometimes be compromised -- requiring a certificate to be\nrevoked and a new one issued.\n\nCert manager makes all these processes relatively straightforward by introducing\nnew Kubernetes resources for certificate issuers and certificates. These\nresource types radically simplify the management of certificates: their\ncreation, expiry and revocation.\n\nMoreover, Cert manager makes it feasible to adopt mutual TLS (mTLS) as an\nauthorization strategy in Kafka based solution.\n\n\n### Prometheus\n\nPrometheus is used in conjunction with Grafana.  It stores the different component's metrics as a set of tuples in a time-series , which allows it to\nbe subsequently used to create Grafana views to assist with monitoring Kafka brokers, MQ queue managers, schema registry....\n\n---\n\n### Kustomize\n\nKubernetes resources have their operational properties defined using YAMLs. As these resources move through\nenvironments such as dev, stage and prod, [Kustomize](https://kustomize.io/) provides a natural way to\nadapt (*customize*!) these YAMLs to these environments.  For example, we might\nwant to change the CPU or memory available to a service in a production\nenvironment compared to a development environment.\n\nBecause [Kustomize](https://kustomize.io/) is built into the `kubectl` and `oc`\ncommands via the `-k` option, it makes configuration management both easy and\nnatural.\n\n---\n\n### GitHub\n\nThis popular version control system is based on git and stores the event-driven\napplication source code and configuration as well as the other\nKubernetes resources. By keeping our event-driven applications and \nconfigurations in Git, and using that to build, test and deploy our\napplications to the Kubernetes cluster, we have a **single\nsource of truth** -- what's in Git is running in the cluster.\n\nMoreover, by using Git operations such as *pull*, *push* and *merge* to make\nchanges, we can exploit the extensive governance and change control provided by\nGit when managing our event-driven solution estate.\n\n---\n\n### OpenShift (Kubernetes) Cluster\n\nThis is the \"operating system\" used to orchestrate our applications and related component containers. Kubernetes is portable across\non-premise and cloud systems and allows us to easily scale our workloads across\nthese environments as required.\n\n---\n\n## High-level architecture view\n\nUsing a GitOps approach we can design a high-level architecture view for the deployment\nof all the previously listed components. \nIt is important to recall that most of the RedHat and IBM products used in event-driven solution\nare using Operators and Custom resources manifests to deploy operands.\n\n**[Operator](https://github.com/operator-framework)** is a long running process that performs products (Operands) deployment and Day 2 operations, like upgrades, failover, or scaling. \nOperator is constantly watching your cluster’s desired state for the software installed. \nHelm and Operators represent two different phases in managing complex application workloads \non Kubernetes. Helm’s primary focus is on the day-1 operation of deploying Kubernetes \nartifacts in a cluster. The ‘domain’ that it understands is that of Kubernetes YAMLs that \nare composed of available Kubernetes Resources / APIs. Operators, on the other hand, are \nprimarily focused on addressing day-2 management tasks of stateful / complex workloads \nsuch as Postgres, Cassandra, Spark, Kafka, SSL Cert Mgmt etc. on Kubernetes.\n\n**Operator Lifecycle Manager (OLM)** helps you to deploy, and update, and generally \nmanage the lifecycle of all of the Operators (and their associated services) running \nacross your clusters\n\nThe Operators deployment is part of a bootstraping step of the GitOps process. We are using a special \nGit repository to manage a catalog of operator definitions/ subscriptions. This is the goal\nof the [eda-gitops-catalog](https://github.com/ibm-cloud-architecture/eda-gitops-catalog) repository.\n\nA solution will have a specific gitops repository that manages services (operands) and application\nspecifics deployment manifests.\n\nWith this base, the following figure illustrates a potential architecture:\n\n![](./images/hl-view.png)\n\n(*the source code of this diagram is a ``.drawio` format and is in the [diagrams folder](https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/src/pages/use-cases/gitops/diagrams).*)\n\nHere are the assumptions we define for any event-driven solution:\n\n* Single admin team for OCP cluster and production projects within the cluster.\n* Developers manages staging and dev environment. This is a functional team developing the solution\n* For the solution one gitops will define all environments and apps/services of the solution.  \n* Developers will not have access to OpenShift cluster administration\n* Cloud Pak for integration operators are installed in all namespaces, and there is only one instance of\neach operator. \n* Only one Platform Navigator installed per cluster (in all namespaces) and it displays instances of\n capabilities from the whole cluster.\n* `ibm-common-services` is unique to the cluster. \n\nFor real production deployment, the production OpenShift cluster will be separated from dev and staging, running in different infrastructure, but using the same\ngithub source. The top-right cluster is for dev and staging, and each of those environmentd will be in different namespace.\nTo enforce isolation and clear separation of concern, each of those `dev` or `staging` namespace, may have Event Streams, MQ brokers, schema registry deployed.\n\nThe `openshift-operators` is used to deploy Operators that manage multiple namespaces.\nThe `openshift-gitops` is for the ArgoCD server and the ArgoCD apps.\n\n\n### GitOps Model\n\n[Gitops](https://www.gitops.tech/) is a way of implementing Continuous Deployment for containerized applications.\n\nThe core idea of GitOps is having a Git repository that always contains declarative descriptions \nof the infrastructure currently desired in the production environment and an automated process \nto make the production environment matches the described state in the repository.\n\nFrom the diagram above, we can see two main components that are essentials to a\nproduction-ready event-driven solution deployment:\n\n* A Kubernetes cluster containing:\n\n    * event-driven applications per namespace / project to facilitate isolation\n    * Event Streams, API mangement, MQ operators per namespace / project \n    * Kafka brokers, Kafka connect, mirror maker, schema registry, End point event gateway, API manager, MQ queue managers per namespace / project \n    * OpenShit GitOps, Pipelines,...\n\n* GitHub as a source of truth for the cluster runtime containing:\n\n    * application source with schema definitions\n    * application configuration\n    * Kafka Cluster configuration\n    * Topic configuration\n    * OpenAPI and AsyncAPI documents\n    * Kafka Connnector configuration\n    * Mirror maker configuration\n    * Queue manager configuration\n\n### GitHub repositories\n\nWe propose to use one GitOps Catalog to centralize the Operator subscription definitions with Kustomize overlays to control operator versioning. \nAn example of such catalog is the [eda-gitops-catalog](https://github.com/ibm-cloud-architecture/eda-gitops-catalog).\nEach operator is defined with the subscription manifest and then overlays to change the product version. Here is an example for Event Streams:\n\n```sh\n├── event-streams\n│   │   ├── README.md\n│   │   └── operator\n│   │       ├── base\n│   │       │   ├── kustomization.yaml\n│   │       │   └── subscription.yaml\n│   │       └── overlays\n│   │           ├── kustomization.yaml\n│   │           ├── v2.3\n│   │           │   ├── kustomization.yaml\n│   │           │   └── patch-channel.yaml\n│   │           ├── v2.4\n│   │           │   ├── kustomization.yaml\n│   │           │   └── patch-channel.yaml\n│   │           └── v2.5\n│   │               ├── kustomization.yaml\n│   │               └── patch-channel.yaml\n```\n\nThe subscription.yam is classical operator definition:\n\n```yaml\napiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: ibm-eventstreams\n  namespace: openshift-operators\nspec:\n  channel: stable\n  name: ibm-eventstreams\n  installPlanApproval: Automatic\n  source: ibm-operator-catalog\n  sourceNamespace: openshift-marketplace\n```\n\nAnd then each overlays use this manifest as a base resource and apply patch for channel and version:\n\n```yaml\n# kustomization.yaml under an overlays\nbases:\n  - ../../base\n\npatchesJson6902:\n- path: patch-channel.yaml\n  target:\n    kind: Subscription\n    name: ibm-eventstreams\n```\n\n```yaml\n# patch-channel.yaml\n- op: replace\n  path: /metadata/namespace\n  value: cp4i\n- op: replace\n  path: /spec/channel\n  value: v2.5\n- op: replace\n  path: /spec/startingCSV\n  value: ibm-eventstreams.v2.5.1\n```\n\nThe second major GitOps will be for the solution itself. We use [KAM CLI](https://github.com/redhat-developer/kam) to bootstrap its creation.\nKAM's goal is to help creating a GitOps project for an existing application as \n[day 1 operations](https://github.com/redhat-developer/kam/tree/master/docs/journey/day1) \nand then add more services as part of `day 2 operation`.\n\n## Examples of solution GitOps\n\nThe following solution GitOps repositories are illustrating the proposed approach:\n\n* [refarch-kc-gitops](https://github.com/ibm-cloud-architecture/refarch-kc-gitops): For the shipping fresh food overseas solution we have defined. It includes\nthe SAGA choreography pattern implemented with Kafka\n* [eda-kc-gitops](https://github.com/ibm-cloud-architecture/eda-kc-gitops): For the shipping fresh food overseas solution we have defined. It includes\nthe SAGA orchestration pattern implemented with MQ\n* [eda-rt-inventory-gitops](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops) to deploy the demo of real-time inventory\n\nAs a lab example, you may want to clone the real-time inventory demo and bootstrap the GitOps apps to deploy services and apps:\n\n```sh\ngit clone https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops\n```\n\nSee the main readme for up to date instructions. All the images are in the public image registry: `quay.io/ibmcase`\n","type":"Mdx","contentDigest":"764c9674aff9a38b0d5df587f55010c5","owner":"gatsby-plugin-mdx","counter":892},"frontmatter":{"title":"Event-driven solution GitOps approach","description":"Event-driven solution GitOps approach"},"exports":{},"rawBody":"---\ntitle: Event-driven solution GitOps approach\ndescription: Event-driven solution GitOps approach\n---\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 2/15/2022</strong>\n</InlineNotification>\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Components for GitOps</AnchorLink>\n  <AnchorLink>High-level architecture view</AnchorLink>\n  <AnchorLink>Examples of solution GitOps</AnchorLink>\n</AnchorLinks>\n\n**Audience**: Architects, Application developers, Site reliability engineers, Administrators\n\n## Overview\n\nThe purpose of the tutorial is to teach architects, developers and operations staff how to deploy a production-ready \nevent-driven solution  [OpenShift Container Platform](http://openshift.com). It makes\nextensive use of the [IBM Cloud Pak for Integration\n(CP4I)](https://cloud.ibm.com/docs/cloud-pak-integration) and other [cloud\nnative technologies]((https://landscape.cncf.io/)) such as Tekton, Kustomize,\nArgoCD, Prometheus, Grafana and Kibana.\n\nGitOps is a declarative way to implement continuous deployment for cloud-native applications. The Red Hat® OpenShift® Container \nPlatform offers the [OpenShift GitOps operator](https://docs.openshift.com/container-platform/4.7/cicd/gitops/understanding-openshift-gitops.html), \nwhich manages the entire lifecycle for [Argo CD](https://argoproj.github.io/argo-cd/) and its components.\n\n\nArgo applications are added to the Argo CD server. An application defines the source of the Kubernetes resources and the target cluster where \nthose resources should be deployed. The Argo CD server \"installs\" a Cloud Pak by synchronizing the applications representing the Cloud Pak into \nthe target cluster.\n\n### System context\n\nA [system context](https://en.wikipedia.org/wiki/System_context_diagram) diagram\nhelps us understand how our system interacts with its different users and\nother systems. For a generic event-driven solution the diagram looks like\n\n![system-context](./images/eda-gitops.png)\n\nWe can see the different entities that interact with a typical event-driven solution deployment.\nThese include users as well as applications and messaging as a service infrastructure which includes\nevent backbone, queueing systems, schema registry, API management, governance platform and monitoring components.\n\nWe'll be developing the Event-driven solution deployment at the centre of the diagram. We can see\nthat it connects applications to systems and infrastructure. Its users are at least\ndevelopers, SREs, Kubernetes administrators, architects...\n\n## Components for GitOps\n\nThe following diagram shows the technical components used in a typical event-driven solution production\ndeployment.\n\n![components](./images/components.png)\n(*the source code of this diagram is a ``.drawio` format and is in the [diagrams folder](https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/src/pages/use-cases/gitops/diagrams).*)\n\nThe diagram organizes the components according to when they are introduced in system development (earlier or later) \nand whether they are a relatively high level application-oriented component, or a relatively low level system- oriented component.\nFor example, GitHub is a system component that is fundamental to how we structure the event-driven solution deployment. \nIn contrast, streaming or event-driven applications are higher level components, and requires other components to be deployed prior to them.\n\nThe color coding illustrates that blue components are part of the solution, red are part of the GitOps on OpenShift and green components\nare externals to OpenShit cluster, most likely event if they could be.\nKustomize represents way to define deployment, and Sealed secret is a service to manage secrets.\n\nAs part of the later components to deploy, we have addressed everything to monitor the solution and the infrastructure. \n\nHere is a brief introduction of those components:\n\n### Event-driven applications\n\nThose applications are supporting business logic, microservice based, and using Reactive messaging, MQ or Kafka APIs. Those applications \nprovide OpenAPIs to the mobile or web applications but also AsyncAPI when they produce events to Kafka or messages to MQ. OpenAPI and AsyncAPI\ndefinitions are managed by API manager and event end-point manager. \n\nSchema definitions are managed by a **Schema Registry**.\n\n--- \n\n### Event-streaming applications\n\nThose applications are also supporting business logic, but more with stateful processing using [Kafka Stream](/technology/kafka-streams/) APIs or \ndifferent product such as [Apache Flink](/technology/flink/).\n\n---\n\n### Queue manager\n\nA queue manager provides queueing services via one of the many MQ APIs. A queue\nmanager hosts the queues that store the messages produced and consumed by\nconnected applications and systems. Queue managers can be connected together via\nnetwork channels to allow messages to flow between disparate systems and\napplications on different platforms including on-premise and cloud systems.\n\n---\n\n## OpenShift GitOps or ArgoCD\n\nOpenShift GitOps (ArgoCD) is used for the continuous deployment of software components to the\nKubernetes cluster. OpenShift GitOps watches a Git repository for new or changed\nKubernetes resource definitions, and applies them to a cluster. In this\nway, OpenShift GitOps ensures that the component configuration stored in GitHub always\nreflects the state of the cluster.\n\nOpenShift GitOps also has the added benefit of being able to monitor resources that it has\ndeployed to ensure that if they drift from their desired values, they will be\nautomatically restored to those values by OpenShift GitOps.\n\n---\n\n### OpenShift Pipelines or Tekton\n\nOpenShift Pipelines (Tekton) is used to automate manual tasks using the concept of a pipeline. A\npipeline comprises a set of tasks that are executed in a specified order in\norder to accomplish a specific objective.\n\nWe use pipelines as part of the continuous integration process to build, test\nand deliver event-driven applications ready for deployment by OpenShift GitOps.\n\n\n### Queue manager\n\nA queue manager provides queueing services via one of the many MQ APIs. A queue\nmanager hosts the queues that store the messages produced and consumed by\nconnected applications and systems. Queue managers can be connected together via\nnetwork channels to allow messages to flow between disparate systems and\napplications on different platforms including on-premise and cloud systems.\n\n---\n\n### Sealed secrets\n\nVery often a component has a Kubernetes secret associated with it. Inside the\nsecret might be a private key to access the IBM entitled container registry, for\nexample.  For obvious reasons, we don't want to store the secrets in GitHub with\nthe rest of the configuration.\n\nA [sealed secret](https://github.com/bitnami-labs/sealed-secrets) solves this problem by introducing a new kind of Kubernetes\nresource. A sealed secret is created from a regular secret, and can be safely\nstored in a Git repository. A deployment time, the sealed secret controller will\nrecreate the secret in its original form so that it can be access by components\nwith the appropriate RBAC authority.\n\n---\n\n### Image Registry\n\nOpenShift contains a registry for storing container images. Images are built and stored by OpenShift Pipelines\n as part of the CICD process. Tekton pipelines and ArgoCD also retrieve\nthe latest best images from the image registry to ensure that what's being\ntested or deployed in higher environments is the same as what's tested in\ndevelopment environments.\n\nWe often refer to uploading images as *pushing* and downloading images as\n*pulling*.\n\n---\n\n### Cert manager\n\nManaging certificates is a difficult process; certificate creation requires a\nCertificate Authority (CA), certificates expire after a period of time, and\nprivate keys can sometimes be compromised -- requiring a certificate to be\nrevoked and a new one issued.\n\nCert manager makes all these processes relatively straightforward by introducing\nnew Kubernetes resources for certificate issuers and certificates. These\nresource types radically simplify the management of certificates: their\ncreation, expiry and revocation.\n\nMoreover, Cert manager makes it feasible to adopt mutual TLS (mTLS) as an\nauthorization strategy in Kafka based solution.\n\n\n### Prometheus\n\nPrometheus is used in conjunction with Grafana.  It stores the different component's metrics as a set of tuples in a time-series , which allows it to\nbe subsequently used to create Grafana views to assist with monitoring Kafka brokers, MQ queue managers, schema registry....\n\n---\n\n### Kustomize\n\nKubernetes resources have their operational properties defined using YAMLs. As these resources move through\nenvironments such as dev, stage and prod, [Kustomize](https://kustomize.io/) provides a natural way to\nadapt (*customize*!) these YAMLs to these environments.  For example, we might\nwant to change the CPU or memory available to a service in a production\nenvironment compared to a development environment.\n\nBecause [Kustomize](https://kustomize.io/) is built into the `kubectl` and `oc`\ncommands via the `-k` option, it makes configuration management both easy and\nnatural.\n\n---\n\n### GitHub\n\nThis popular version control system is based on git and stores the event-driven\napplication source code and configuration as well as the other\nKubernetes resources. By keeping our event-driven applications and \nconfigurations in Git, and using that to build, test and deploy our\napplications to the Kubernetes cluster, we have a **single\nsource of truth** -- what's in Git is running in the cluster.\n\nMoreover, by using Git operations such as *pull*, *push* and *merge* to make\nchanges, we can exploit the extensive governance and change control provided by\nGit when managing our event-driven solution estate.\n\n---\n\n### OpenShift (Kubernetes) Cluster\n\nThis is the \"operating system\" used to orchestrate our applications and related component containers. Kubernetes is portable across\non-premise and cloud systems and allows us to easily scale our workloads across\nthese environments as required.\n\n---\n\n## High-level architecture view\n\nUsing a GitOps approach we can design a high-level architecture view for the deployment\nof all the previously listed components. \nIt is important to recall that most of the RedHat and IBM products used in event-driven solution\nare using Operators and Custom resources manifests to deploy operands.\n\n**[Operator](https://github.com/operator-framework)** is a long running process that performs products (Operands) deployment and Day 2 operations, like upgrades, failover, or scaling. \nOperator is constantly watching your cluster’s desired state for the software installed. \nHelm and Operators represent two different phases in managing complex application workloads \non Kubernetes. Helm’s primary focus is on the day-1 operation of deploying Kubernetes \nartifacts in a cluster. The ‘domain’ that it understands is that of Kubernetes YAMLs that \nare composed of available Kubernetes Resources / APIs. Operators, on the other hand, are \nprimarily focused on addressing day-2 management tasks of stateful / complex workloads \nsuch as Postgres, Cassandra, Spark, Kafka, SSL Cert Mgmt etc. on Kubernetes.\n\n**Operator Lifecycle Manager (OLM)** helps you to deploy, and update, and generally \nmanage the lifecycle of all of the Operators (and their associated services) running \nacross your clusters\n\nThe Operators deployment is part of a bootstraping step of the GitOps process. We are using a special \nGit repository to manage a catalog of operator definitions/ subscriptions. This is the goal\nof the [eda-gitops-catalog](https://github.com/ibm-cloud-architecture/eda-gitops-catalog) repository.\n\nA solution will have a specific gitops repository that manages services (operands) and application\nspecifics deployment manifests.\n\nWith this base, the following figure illustrates a potential architecture:\n\n![](./images/hl-view.png)\n\n(*the source code of this diagram is a ``.drawio` format and is in the [diagrams folder](https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/src/pages/use-cases/gitops/diagrams).*)\n\nHere are the assumptions we define for any event-driven solution:\n\n* Single admin team for OCP cluster and production projects within the cluster.\n* Developers manages staging and dev environment. This is a functional team developing the solution\n* For the solution one gitops will define all environments and apps/services of the solution.  \n* Developers will not have access to OpenShift cluster administration\n* Cloud Pak for integration operators are installed in all namespaces, and there is only one instance of\neach operator. \n* Only one Platform Navigator installed per cluster (in all namespaces) and it displays instances of\n capabilities from the whole cluster.\n* `ibm-common-services` is unique to the cluster. \n\nFor real production deployment, the production OpenShift cluster will be separated from dev and staging, running in different infrastructure, but using the same\ngithub source. The top-right cluster is for dev and staging, and each of those environmentd will be in different namespace.\nTo enforce isolation and clear separation of concern, each of those `dev` or `staging` namespace, may have Event Streams, MQ brokers, schema registry deployed.\n\nThe `openshift-operators` is used to deploy Operators that manage multiple namespaces.\nThe `openshift-gitops` is for the ArgoCD server and the ArgoCD apps.\n\n\n### GitOps Model\n\n[Gitops](https://www.gitops.tech/) is a way of implementing Continuous Deployment for containerized applications.\n\nThe core idea of GitOps is having a Git repository that always contains declarative descriptions \nof the infrastructure currently desired in the production environment and an automated process \nto make the production environment matches the described state in the repository.\n\nFrom the diagram above, we can see two main components that are essentials to a\nproduction-ready event-driven solution deployment:\n\n* A Kubernetes cluster containing:\n\n    * event-driven applications per namespace / project to facilitate isolation\n    * Event Streams, API mangement, MQ operators per namespace / project \n    * Kafka brokers, Kafka connect, mirror maker, schema registry, End point event gateway, API manager, MQ queue managers per namespace / project \n    * OpenShit GitOps, Pipelines,...\n\n* GitHub as a source of truth for the cluster runtime containing:\n\n    * application source with schema definitions\n    * application configuration\n    * Kafka Cluster configuration\n    * Topic configuration\n    * OpenAPI and AsyncAPI documents\n    * Kafka Connnector configuration\n    * Mirror maker configuration\n    * Queue manager configuration\n\n### GitHub repositories\n\nWe propose to use one GitOps Catalog to centralize the Operator subscription definitions with Kustomize overlays to control operator versioning. \nAn example of such catalog is the [eda-gitops-catalog](https://github.com/ibm-cloud-architecture/eda-gitops-catalog).\nEach operator is defined with the subscription manifest and then overlays to change the product version. Here is an example for Event Streams:\n\n```sh\n├── event-streams\n│   │   ├── README.md\n│   │   └── operator\n│   │       ├── base\n│   │       │   ├── kustomization.yaml\n│   │       │   └── subscription.yaml\n│   │       └── overlays\n│   │           ├── kustomization.yaml\n│   │           ├── v2.3\n│   │           │   ├── kustomization.yaml\n│   │           │   └── patch-channel.yaml\n│   │           ├── v2.4\n│   │           │   ├── kustomization.yaml\n│   │           │   └── patch-channel.yaml\n│   │           └── v2.5\n│   │               ├── kustomization.yaml\n│   │               └── patch-channel.yaml\n```\n\nThe subscription.yam is classical operator definition:\n\n```yaml\napiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: ibm-eventstreams\n  namespace: openshift-operators\nspec:\n  channel: stable\n  name: ibm-eventstreams\n  installPlanApproval: Automatic\n  source: ibm-operator-catalog\n  sourceNamespace: openshift-marketplace\n```\n\nAnd then each overlays use this manifest as a base resource and apply patch for channel and version:\n\n```yaml\n# kustomization.yaml under an overlays\nbases:\n  - ../../base\n\npatchesJson6902:\n- path: patch-channel.yaml\n  target:\n    kind: Subscription\n    name: ibm-eventstreams\n```\n\n```yaml\n# patch-channel.yaml\n- op: replace\n  path: /metadata/namespace\n  value: cp4i\n- op: replace\n  path: /spec/channel\n  value: v2.5\n- op: replace\n  path: /spec/startingCSV\n  value: ibm-eventstreams.v2.5.1\n```\n\nThe second major GitOps will be for the solution itself. We use [KAM CLI](https://github.com/redhat-developer/kam) to bootstrap its creation.\nKAM's goal is to help creating a GitOps project for an existing application as \n[day 1 operations](https://github.com/redhat-developer/kam/tree/master/docs/journey/day1) \nand then add more services as part of `day 2 operation`.\n\n## Examples of solution GitOps\n\nThe following solution GitOps repositories are illustrating the proposed approach:\n\n* [refarch-kc-gitops](https://github.com/ibm-cloud-architecture/refarch-kc-gitops): For the shipping fresh food overseas solution we have defined. It includes\nthe SAGA choreography pattern implemented with Kafka\n* [eda-kc-gitops](https://github.com/ibm-cloud-architecture/eda-kc-gitops): For the shipping fresh food overseas solution we have defined. It includes\nthe SAGA orchestration pattern implemented with MQ\n* [eda-rt-inventory-gitops](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops) to deploy the demo of real-time inventory\n\nAs a lab example, you may want to clone the real-time inventory demo and bootstrap the GitOps apps to deploy services and apps:\n\n```sh\ngit clone https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops\n```\n\nSee the main readme for up to date instructions. All the images are in the public image registry: `quay.io/ibmcase`\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/use-cases/gitops/index.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}